# Minimal settings for development and for ModelManager to pick up model configs
prompt_builder:
  # Directory (relative to PROJECT_ROOT) where prompt YAML templates are stored
  templates_dir: prompts/prompt_files

mcp:
  weather:
    base_url: "https://api.openweathermap.org/data/2.5/weather"
    api_key: "6857620b61dbecab1900a512355c85b0"
    module: "weather_service"
    port: 8000
    server_url: "http://localhost:8000/mcp"
    tool_name: get_weather

models:
  WhisperMediumInfer:
    model_name: "openai/whisper-medium"
    samplerate: 16000
    device: "cpu"
  OpenAIWhisperTinyInfer:
    model_name: "openai/whisper-tiny"
    samplerate: 16000
  QwenV25Infer:
    model_name: "Qwen/Qwen2.5-VL-3B-Instruct"
    device: "mps"
  SentenceEmbedderInfer:
    model_name: "all-MiniLM-L6-v2"
    device: "mps"
  GLiNERInfer:
    model_name: "urchade/gliner_base"
    device: "mps"
  SpeakerEmbeddingInfer:
    model_name: "speechbrain/spkrec-ecapa-voxceleb"
  SpeechT5TTSInfer:
    model_name: "microsoft/speecht5_tts"
    vocoder_name: "microsoft/speecht5_hifigan"
    samplerate: 16000
    device: "cpu"

memory:
  dir: "{project_root}/.memory/"

db:
  audio_recogniser: "{project_root}/.cache/audio_embeddings.npz"

# Path (absolute or repo-relative) to a speaker embedding .npy file used by TTS.
# If empty or null, TTS will run without a speaker embedding (neutral voice).
tts:
  embedding_path: "{project_root}/artefacts/tts_kn.npy"
